{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Customers Demographic Analysis for Auto Rental Company\n",
    "### Data Engineering Capstone Project\n",
    "\n",
    "#### Project Summary\n",
    "We create a data model to allow auto rental company to examine the demographics of its potential customers that are visitors to US from other countries. They are able to query this database to know the demographics of US travelers including the percentage of each travel purpose, the airline they choose, arrival time, stay length, age, nationality, occupation, and temperature of their destination etc. By knowing these, the auto rental company may better tailor their marketing and advertisement messages to the customers who may need the car rental the most and provide the tailored service and auto inventory to these customers. \n",
    "\n",
    "\n",
    "The project follows the following steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Do all imports and installs here\n",
    "import pandas as pd\n",
    "from pyspark.sql import functions as f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 1: Scope the Project and Gather Data\n",
    "\n",
    "#### Scope \n",
    "We pull together from 4 different sources and create total 8 fact and dimension table with star schema to allow fast querying to check on the potential customer demographic like number of visitors to each city, their nationality, and age etc. We use Spark as the tool to perfor ETL and create these tables. \n",
    "\n",
    "#### Describe and Gather Data \n",
    "The data sources include the following:\n",
    "1. I94 Foriegn Visitor/Immigration Data: This is in SAS file format which contain information about each foreign visitor's information such as age, travel mode, gender, and destination airport etc. The data comes from the US National Touris and Trade Office. \n",
    "\n",
    "2. US Cities Demographics: This data has each US City's demographics include median age, population count by gender and race, and average household size etc. The data is stored in csv file format from OpenSoft.   \n",
    "\n",
    "3. Airport Code Table: This data contains airport codes and corresponding cities. It is downloaded from [here](https://datahub.io/core/airport-codes#data).\n",
    "\n",
    "4. World Temperature Data: This data contains average temperature every day for each city in the world. The dataset is from Kaggle [here](https://www.kaggle.com/berkeleyearth/climate-change-earth-surface-temperature-data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.\\\n",
    "config(\"spark.jars.packages\",\"saurfang:spark-sas7bdat:2.0.0-s_2.11\")\\\n",
    ".enableHiveSupport().getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# To display all columns on pandas dataframe\n",
    "pd.set_option('max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>depdate</th>\n",
       "      <th>i94bir</th>\n",
       "      <th>i94visa</th>\n",
       "      <th>count</th>\n",
       "      <th>dtadfile</th>\n",
       "      <th>visapost</th>\n",
       "      <th>occup</th>\n",
       "      <th>entdepa</th>\n",
       "      <th>entdepd</th>\n",
       "      <th>entdepu</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>insnum</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>692.0</td>\n",
       "      <td>692.0</td>\n",
       "      <td>XXX</td>\n",
       "      <td>20573.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>T</td>\n",
       "      <td>None</td>\n",
       "      <td>U</td>\n",
       "      <td>None</td>\n",
       "      <td>1979.0</td>\n",
       "      <td>10282016</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1.897628e+09</td>\n",
       "      <td>None</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>276.0</td>\n",
       "      <td>ATL</td>\n",
       "      <td>20551.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20130811</td>\n",
       "      <td>SEO</td>\n",
       "      <td>None</td>\n",
       "      <td>G</td>\n",
       "      <td>None</td>\n",
       "      <td>Y</td>\n",
       "      <td>None</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>D/S</td>\n",
       "      <td>M</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>3.736796e+09</td>\n",
       "      <td>00296</td>\n",
       "      <td>F1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>WAS</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MI</td>\n",
       "      <td>20691.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160401</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>T</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1961.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>M</td>\n",
       "      <td>None</td>\n",
       "      <td>OS</td>\n",
       "      <td>6.666432e+08</td>\n",
       "      <td>93</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MA</td>\n",
       "      <td>20567.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160401</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>AA</td>\n",
       "      <td>9.246846e+10</td>\n",
       "      <td>00199</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MA</td>\n",
       "      <td>20567.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160401</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>AA</td>\n",
       "      <td>9.246846e+10</td>\n",
       "      <td>00199</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cicid   i94yr  i94mon  i94cit  i94res i94port  arrdate  i94mode i94addr  \\\n",
       "0    6.0  2016.0     4.0   692.0   692.0     XXX  20573.0      NaN    None   \n",
       "1    7.0  2016.0     4.0   254.0   276.0     ATL  20551.0      1.0      AL   \n",
       "2   15.0  2016.0     4.0   101.0   101.0     WAS  20545.0      1.0      MI   \n",
       "3   16.0  2016.0     4.0   101.0   101.0     NYC  20545.0      1.0      MA   \n",
       "4   17.0  2016.0     4.0   101.0   101.0     NYC  20545.0      1.0      MA   \n",
       "\n",
       "   depdate  i94bir  i94visa  count  dtadfile visapost occup entdepa entdepd  \\\n",
       "0      NaN    37.0      2.0    1.0      None     None  None       T    None   \n",
       "1      NaN    25.0      3.0    1.0  20130811      SEO  None       G    None   \n",
       "2  20691.0    55.0      2.0    1.0  20160401     None  None       T       O   \n",
       "3  20567.0    28.0      2.0    1.0  20160401     None  None       O       O   \n",
       "4  20567.0     4.0      2.0    1.0  20160401     None  None       O       O   \n",
       "\n",
       "  entdepu matflag  biryear   dtaddto gender insnum airline        admnum  \\\n",
       "0       U    None   1979.0  10282016   None   None    None  1.897628e+09   \n",
       "1       Y    None   1991.0       D/S      M   None    None  3.736796e+09   \n",
       "2    None       M   1961.0  09302016      M   None      OS  6.666432e+08   \n",
       "3    None       M   1988.0  09302016   None   None      AA  9.246846e+10   \n",
       "4    None       M   2012.0  09302016   None   None      AA  9.246846e+10   \n",
       "\n",
       "   fltno visatype  \n",
       "0   None       B2  \n",
       "1  00296       F1  \n",
       "2     93       B2  \n",
       "3  00199       B2  \n",
       "4  00199       B2  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Import immigration data\n",
    "df_spark =spark.read.format('com.github.saurfang.sas.spark').load('../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat')\n",
    "df_spark.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#write to parquet\n",
    "#df_spark.write.parquet(\"sas_data\")\n",
    "#df_spark=spark.read.parquet(\"sas_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row Count 3096313\n",
      "root\n",
      " |-- cicid: double (nullable = true)\n",
      " |-- i94yr: double (nullable = true)\n",
      " |-- i94mon: double (nullable = true)\n",
      " |-- i94cit: double (nullable = true)\n",
      " |-- i94res: double (nullable = true)\n",
      " |-- i94port: string (nullable = true)\n",
      " |-- arrdate: double (nullable = true)\n",
      " |-- i94mode: double (nullable = true)\n",
      " |-- i94addr: string (nullable = true)\n",
      " |-- depdate: double (nullable = true)\n",
      " |-- i94bir: double (nullable = true)\n",
      " |-- i94visa: double (nullable = true)\n",
      " |-- count: double (nullable = true)\n",
      " |-- dtadfile: string (nullable = true)\n",
      " |-- visapost: string (nullable = true)\n",
      " |-- occup: string (nullable = true)\n",
      " |-- entdepa: string (nullable = true)\n",
      " |-- entdepd: string (nullable = true)\n",
      " |-- entdepu: string (nullable = true)\n",
      " |-- matflag: string (nullable = true)\n",
      " |-- biryear: double (nullable = true)\n",
      " |-- dtaddto: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- insnum: string (nullable = true)\n",
      " |-- airline: string (nullable = true)\n",
      " |-- admnum: double (nullable = true)\n",
      " |-- fltno: string (nullable = true)\n",
      " |-- visatype: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Row Count', df_spark.count())\n",
    "df_spark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Code</th>\n",
       "      <th>Country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>582</td>\n",
       "      <td>MEXICO Air Sea, and Not Reported (I-94, no lan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>236</td>\n",
       "      <td>AFGHANISTAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101</td>\n",
       "      <td>ALBANIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>316</td>\n",
       "      <td>ALGERIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>102</td>\n",
       "      <td>ANDORRA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Code                                            Country\n",
       "0  582  MEXICO Air Sea, and Not Reported (I-94, no lan...\n",
       "1  236                                        AFGHANISTAN\n",
       "2  101                                            ALBANIA\n",
       "3  316                                            ALGERIA\n",
       "4  102                                            ANDORRA"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import mapping table for i94res to nationality\n",
    "df_nation =spark.read.format('csv').option('header', 'true').load('immigration_nationality.csv')\n",
    "df_nation.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row Count 289\n",
      "root\n",
      " |-- Code: string (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Row Count', df_nation.count())\n",
    "df_nation.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State_abbr</th>\n",
       "      <th>State_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AL</td>\n",
       "      <td>ALABAMA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AK</td>\n",
       "      <td>ALASKA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AZ</td>\n",
       "      <td>ARIZONA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AR</td>\n",
       "      <td>ARKANSAS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CA</td>\n",
       "      <td>CALIFORNIA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  State_abbr  State_name\n",
       "0         AL     ALABAMA\n",
       "1         AK      ALASKA\n",
       "2         AZ     ARIZONA\n",
       "3         AR    ARKANSAS\n",
       "4         CA  CALIFORNIA"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import mapping table for state abbreviation to state name\n",
    "df_state =spark.read.format('csv').option('header', 'true').load('state.csv')\n",
    "df_state.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row Count 55\n",
      "root\n",
      " |-- State_abbr: string (nullable = true)\n",
      " |-- State_name: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Row Count', df_state.count())\n",
    "df_state.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Capitalize the first letter of the state name for consistency\n",
    "\n",
    "df_state = df_state.withColumn(\"State_name_2\",  f.initcap(df_state.State_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State_abbr</th>\n",
       "      <th>State_name</th>\n",
       "      <th>State_name_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AL</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>Alabama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AK</td>\n",
       "      <td>ALASKA</td>\n",
       "      <td>Alaska</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AZ</td>\n",
       "      <td>ARIZONA</td>\n",
       "      <td>Arizona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AR</td>\n",
       "      <td>ARKANSAS</td>\n",
       "      <td>Arkansas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CA</td>\n",
       "      <td>CALIFORNIA</td>\n",
       "      <td>California</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  State_abbr  State_name State_name_2\n",
       "0         AL     ALABAMA      Alabama\n",
       "1         AK      ALASKA       Alaska\n",
       "2         AZ     ARIZONA      Arizona\n",
       "3         AR    ARKANSAS     Arkansas\n",
       "4         CA  CALIFORNIA   California"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_state.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mode_code</th>\n",
       "      <th>mode_desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Air</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Sea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Land</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>Not reported</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  mode_code     mode_desc\n",
       "0         1           Air\n",
       "1         2           Sea\n",
       "2         3          Land\n",
       "3         9  Not reported"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import mapping table for immigration mode\n",
    "df_mode =spark.read.format('csv').option('header', 'true').load('mode.csv')\n",
    "df_mode.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row Count 55\n",
      "root\n",
      " |-- State_abbr: string (nullable = true)\n",
      " |-- State_name: string (nullable = true)\n",
      " |-- State_name_2: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Row Count', df_state.count())\n",
    "df_state.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ident</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>elevation_ft</th>\n",
       "      <th>continent</th>\n",
       "      <th>iso_country</th>\n",
       "      <th>iso_region</th>\n",
       "      <th>municipality</th>\n",
       "      <th>gps_code</th>\n",
       "      <th>iata_code</th>\n",
       "      <th>local_code</th>\n",
       "      <th>coordinates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00A</td>\n",
       "      <td>heliport</td>\n",
       "      <td>Total Rf Heliport</td>\n",
       "      <td>11</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-PA</td>\n",
       "      <td>Bensalem</td>\n",
       "      <td>00A</td>\n",
       "      <td>None</td>\n",
       "      <td>00A</td>\n",
       "      <td>-74.93360137939453, 40.07080078125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00AA</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Aero B Ranch Airport</td>\n",
       "      <td>3435</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-KS</td>\n",
       "      <td>Leoti</td>\n",
       "      <td>00AA</td>\n",
       "      <td>None</td>\n",
       "      <td>00AA</td>\n",
       "      <td>-101.473911, 38.704022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00AK</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Lowell Field</td>\n",
       "      <td>450</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AK</td>\n",
       "      <td>Anchor Point</td>\n",
       "      <td>00AK</td>\n",
       "      <td>None</td>\n",
       "      <td>00AK</td>\n",
       "      <td>-151.695999146, 59.94919968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00AL</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Epps Airpark</td>\n",
       "      <td>820</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AL</td>\n",
       "      <td>Harvest</td>\n",
       "      <td>00AL</td>\n",
       "      <td>None</td>\n",
       "      <td>00AL</td>\n",
       "      <td>-86.77030181884766, 34.86479949951172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00AR</td>\n",
       "      <td>closed</td>\n",
       "      <td>Newport Hospital &amp; Clinic Heliport</td>\n",
       "      <td>237</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AR</td>\n",
       "      <td>Newport</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>-91.254898, 35.6087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ident           type                                name elevation_ft  \\\n",
       "0   00A       heliport                   Total Rf Heliport           11   \n",
       "1  00AA  small_airport                Aero B Ranch Airport         3435   \n",
       "2  00AK  small_airport                        Lowell Field          450   \n",
       "3  00AL  small_airport                        Epps Airpark          820   \n",
       "4  00AR         closed  Newport Hospital & Clinic Heliport          237   \n",
       "\n",
       "  continent iso_country iso_region  municipality gps_code iata_code  \\\n",
       "0        NA          US      US-PA      Bensalem      00A      None   \n",
       "1        NA          US      US-KS         Leoti     00AA      None   \n",
       "2        NA          US      US-AK  Anchor Point     00AK      None   \n",
       "3        NA          US      US-AL       Harvest     00AL      None   \n",
       "4        NA          US      US-AR       Newport     None      None   \n",
       "\n",
       "  local_code                            coordinates  \n",
       "0        00A     -74.93360137939453, 40.07080078125  \n",
       "1       00AA                 -101.473911, 38.704022  \n",
       "2       00AK            -151.695999146, 59.94919968  \n",
       "3       00AL  -86.77030181884766, 34.86479949951172  \n",
       "4       None                    -91.254898, 35.6087  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import table for airport\n",
    "df_airport =spark.read.format('csv').option('header', 'true').load('airport-codes_csv.csv')\n",
    "df_airport.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row Count 55075\n",
      "root\n",
      " |-- ident: string (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- elevation_ft: string (nullable = true)\n",
      " |-- continent: string (nullable = true)\n",
      " |-- iso_country: string (nullable = true)\n",
      " |-- iso_region: string (nullable = true)\n",
      " |-- municipality: string (nullable = true)\n",
      " |-- gps_code: string (nullable = true)\n",
      " |-- iata_code: string (nullable = true)\n",
      " |-- local_code: string (nullable = true)\n",
      " |-- coordinates: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Row Count', df_airport.count())\n",
    "df_airport.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Number of Veterans</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>Average Household Size</th>\n",
       "      <th>State Code</th>\n",
       "      <th>Race</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Silver Spring</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>33.8</td>\n",
       "      <td>40601</td>\n",
       "      <td>41862</td>\n",
       "      <td>82463</td>\n",
       "      <td>1562</td>\n",
       "      <td>30908</td>\n",
       "      <td>2.6</td>\n",
       "      <td>MD</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>25924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quincy</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>41.0</td>\n",
       "      <td>44129</td>\n",
       "      <td>49500</td>\n",
       "      <td>93629</td>\n",
       "      <td>4147</td>\n",
       "      <td>32935</td>\n",
       "      <td>2.39</td>\n",
       "      <td>MA</td>\n",
       "      <td>White</td>\n",
       "      <td>58723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hoover</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>38.5</td>\n",
       "      <td>38040</td>\n",
       "      <td>46799</td>\n",
       "      <td>84839</td>\n",
       "      <td>4819</td>\n",
       "      <td>8229</td>\n",
       "      <td>2.58</td>\n",
       "      <td>AL</td>\n",
       "      <td>Asian</td>\n",
       "      <td>4759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rancho Cucamonga</td>\n",
       "      <td>California</td>\n",
       "      <td>34.5</td>\n",
       "      <td>88127</td>\n",
       "      <td>87105</td>\n",
       "      <td>175232</td>\n",
       "      <td>5821</td>\n",
       "      <td>33878</td>\n",
       "      <td>3.18</td>\n",
       "      <td>CA</td>\n",
       "      <td>Black or African-American</td>\n",
       "      <td>24437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Newark</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>34.6</td>\n",
       "      <td>138040</td>\n",
       "      <td>143873</td>\n",
       "      <td>281913</td>\n",
       "      <td>5829</td>\n",
       "      <td>86253</td>\n",
       "      <td>2.73</td>\n",
       "      <td>NJ</td>\n",
       "      <td>White</td>\n",
       "      <td>76402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               City          State Median Age Male Population  \\\n",
       "0     Silver Spring       Maryland       33.8           40601   \n",
       "1            Quincy  Massachusetts       41.0           44129   \n",
       "2            Hoover        Alabama       38.5           38040   \n",
       "3  Rancho Cucamonga     California       34.5           88127   \n",
       "4            Newark     New Jersey       34.6          138040   \n",
       "\n",
       "  Female Population Total Population Number of Veterans Foreign-born  \\\n",
       "0             41862            82463               1562        30908   \n",
       "1             49500            93629               4147        32935   \n",
       "2             46799            84839               4819         8229   \n",
       "3             87105           175232               5821        33878   \n",
       "4            143873           281913               5829        86253   \n",
       "\n",
       "  Average Household Size State Code                       Race  Count  \n",
       "0                    2.6         MD         Hispanic or Latino  25924  \n",
       "1                   2.39         MA                      White  58723  \n",
       "2                   2.58         AL                      Asian   4759  \n",
       "3                   3.18         CA  Black or African-American  24437  \n",
       "4                   2.73         NJ                      White  76402  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import table for city demographics\n",
    "\n",
    "df_demo =spark.read.format('csv').option('header', 'true').option('delimiter', ';').load('us-cities-demographics.csv')\n",
    "df_demo.limit(5).toPandas()\n",
    "# which city or state is most popular for immigrant.  What's the ratio of immigrate to the total population.  Or how close is the age. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row Count 2891\n",
      "root\n",
      " |-- City: string (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- Median Age: string (nullable = true)\n",
      " |-- Male Population: string (nullable = true)\n",
      " |-- Female Population: string (nullable = true)\n",
      " |-- Total Population: string (nullable = true)\n",
      " |-- Number of Veterans: string (nullable = true)\n",
      " |-- Foreign-born: string (nullable = true)\n",
      " |-- Average Household Size: string (nullable = true)\n",
      " |-- State Code: string (nullable = true)\n",
      " |-- Race: string (nullable = true)\n",
      " |-- Count: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Row Count', df_demo.count())\n",
    "df_demo.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>AverageTemperature</th>\n",
       "      <th>AverageTemperatureUncertainty</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1743-11-01</td>\n",
       "      <td>6.068</td>\n",
       "      <td>1.7369999999999999</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1743-12-01</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1744-01-01</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1744-02-01</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1744-03-01</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dt AverageTemperature AverageTemperatureUncertainty   City  \\\n",
       "0  1743-11-01              6.068            1.7369999999999999  Århus   \n",
       "1  1743-12-01               None                          None  Århus   \n",
       "2  1744-01-01               None                          None  Århus   \n",
       "3  1744-02-01               None                          None  Århus   \n",
       "4  1744-03-01               None                          None  Århus   \n",
       "\n",
       "   Country Latitude Longitude  \n",
       "0  Denmark   57.05N    10.33E  \n",
       "1  Denmark   57.05N    10.33E  \n",
       "2  Denmark   57.05N    10.33E  \n",
       "3  Denmark   57.05N    10.33E  \n",
       "4  Denmark   57.05N    10.33E  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import temperature table for each city\n",
    "\n",
    "path_temp = \"../../data2/GlobalLandTemperaturesByCity.csv\"\n",
    "df_temp =spark.read.format('csv').option('header', 'true').option('delimiter', ',').load(path_temp)\n",
    "df_temp.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row Count 8599212\n",
      "root\n",
      " |-- dt: string (nullable = true)\n",
      " |-- AverageTemperature: string (nullable = true)\n",
      " |-- AverageTemperatureUncertainty: string (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      " |-- Latitude: string (nullable = true)\n",
      " |-- Longitude: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Row Count', df_temp.count())\n",
    "df_temp.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 2: Explore and Assess the Data\n",
    "#### Explore the Data \n",
    "Identify data quality issues, like missing values, duplicate data, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Check the missing value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cicid with null values               0\n",
      "i94yr with null values               0\n",
      "i94mon with null values               0\n",
      "i94cit with null values               0\n",
      "i94res with null values               0\n",
      "i94port with null values               0\n",
      "arrdate with null values               0\n",
      "i94mode with null values             239\n",
      "i94addr with null values          152592\n",
      "depdate with null values          142457\n",
      "i94bir with null values             802\n",
      "i94visa with null values               0\n",
      "count with null values               0\n",
      "dtadfile with null values               1\n",
      "visapost with null values         1881250\n",
      "occup with null values         3088187\n",
      "entdepa with null values             238\n",
      "entdepd with null values          138429\n",
      "entdepu with null values         3095921\n",
      "matflag with null values          138429\n",
      "biryear with null values             802\n",
      "dtaddto with null values             477\n",
      "gender with null values          414269\n",
      "insnum with null values         2982605\n",
      "airline with null values           83627\n",
      "admnum with null values               0\n",
      "fltno with null values           19549\n",
      "visatype with null values               0\n"
     ]
    }
   ],
   "source": [
    "for col in df_spark.columns:\n",
    "  print(col, \"with null values\", \"%15s\" % df_spark.filter(df_spark[col].isNull()).count() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ident with null values               0\n",
      "type with null values               0\n",
      "name with null values               0\n",
      "elevation_ft with null values            7006\n",
      "continent with null values               0\n",
      "iso_country with null values               0\n",
      "iso_region with null values               0\n",
      "municipality with null values            5676\n",
      "gps_code with null values           14045\n",
      "iata_code with null values           45886\n",
      "local_code with null values           26389\n",
      "coordinates with null values               0\n"
     ]
    }
   ],
   "source": [
    "for col in df_airport.columns:\n",
    "  print(col, \"with null values\", \"%15s\" % df_airport.filter(df_airport[col].isNull()).count() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "City with null values               0\n",
      "State with null values               0\n",
      "Median Age with null values               0\n",
      "Male Population with null values               3\n",
      "Female Population with null values               3\n",
      "Total Population with null values               0\n",
      "Number of Veterans with null values              13\n",
      "Foreign-born with null values              13\n",
      "Average Household Size with null values              16\n",
      "State Code with null values               0\n",
      "Race with null values               0\n",
      "Count with null values               0\n"
     ]
    }
   ],
   "source": [
    "for col in df_demo.columns:\n",
    "  print(col, \"with null values\", \"%15s\" % df_demo.filter(df_demo[col].isNull()).count() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dt with null values               0\n",
      "AverageTemperature with null values          364130\n",
      "AverageTemperatureUncertainty with null values          364130\n",
      "City with null values               0\n",
      "Country with null values               0\n",
      "Latitude with null values               0\n",
      "Longitude with null values               0\n"
     ]
    }
   ],
   "source": [
    "for col in df_temp.columns:\n",
    "  print(col, \"with null values\", \"%15s\" % df_temp.filter(df_temp[col].isNull()).count() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### There are quite a few missing values, but let's work on processing our data to narrow down to the data relevant to our project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Airport Table Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row Count 22757\n"
     ]
    }
   ],
   "source": [
    "# Keep only the US airport\n",
    "df_airport_us = df_airport.filter(df_airport['iso_Country'] == 'US')\n",
    "print('Row Count', df_airport_us.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Write a function to see unique value in each field (limit to show part of it)\n",
    "def check_distinct(df, cols):\n",
    "  \"\"\"\n",
    "  A function to show the number of distinct value in each column and show the first 300 distinct value for a quick look and print out.\n",
    "\n",
    "  df (object): the Spark dataframe to check unique value\n",
    "  cols (list of string): the list of string for the column name to check unique value\n",
    "  \n",
    "  \"\"\"  \n",
    "  \n",
    "  for col in cols:\n",
    "    distinct = sorted(list(df.select(col).distinct().toPandas()[col]))\n",
    "    print(col, \"distinct count:\", len(distinct), \"distinct value:\", distinct[:300],\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ident distinct count: 2019 distinct value: ['07FA', '0AK', '0CO2', '0TE7', '13MA', '13Z', '16A', '16K', '19AK', '19P', '1KC', '1O6', '1Z1', '1Z9', '2AK', '2AK3', '2AK6', '2IG4', '2K5', '2TE0', '2Z1', '2Z6', '38WA', '3AK5', '3IS8', '3VS', '3Z8', '4A2', '4AK', '4K0', '4K5', '4KA', '4TE8', '4Z7', '57A', '5A8', '5KE', '5NK', '5Z9', '65LA', '6CA3', '6N5', '6N7', '6OK6', '78K', '78WA', '7KA', '7NC2', '7WA5', '82CL', '83Q', '84CL', '84K', '89NY', '8XS8', '90WA', '96Z', '9A3', '9A8', '9N2', '9Z8', 'A23', 'A61', 'A63', 'A79', 'AHT', 'AK13', 'AK26', 'AK33', 'AK49', 'AK56', 'AK62', 'AK71', 'AK75', 'AK81', 'AK96', 'AK97', 'AL73', 'ALZ', 'AQY', 'ARX', 'AUS', 'AYZ', 'AZ15', 'BBG', 'BCJ', 'BDH', 'BNF', 'BOF', 'BOK', 'BQV', 'BRG', 'BYA', 'BZS', 'CGA', 'CHP', 'CIV', 'CJX', 'CKR', 'CKU', 'CKX', 'CLC', 'CLG', 'CT88', 'CVH', 'CVR', 'CXC', 'CYM', 'CZK', 'CZN', 'CZO', 'D38', 'D66', 'DCK', 'DCR', 'DHB', 'DPK', 'DWS', 'EDA', 'ESP', 'EXI', 'F23', 'FAL', 'FEW', 'FLE', 'FLT', 'FSN', 'GAB', 'GFD', 'GNU', 'GSZ', 'GVE', 'HAY', 'HEY', 'HGT', 'HI01', 'HI07', 'HKB', 'HNE', 'HYL', 'IVH', 'JLA', 'JPB', 'JPN', 'JRA', 'JRB', 'K00C', 'K00F', 'K05U', 'K06U', 'K07', 'K0B8', 'K0K7', 'K0S9', 'K1B1', 'K1F0', 'K1G4', 'K1O2', 'K1O5', 'K1V6', 'K21', 'K23', 'K29', 'K2F0', 'K2O1', 'K2S7', 'K2W6', 'K37V', 'K39N', 'K3C8', 'K3O9', 'K3S8', 'K3TR', 'K3W7', 'K40G', 'K40J', 'K41U', 'K44U', 'K47N', 'K4R7', 'K4S1', 'K50I', 'K5N2', 'K5T9', 'K61B', 'K67L', 'K6D9', 'K6S2', 'K74S', 'K74V', 'K7G9', 'K7V2', 'K80F', 'K8A6', 'K9U3', 'KAAF', 'KAAP', 'KABE', 'KABI', 'KABQ'] \n",
      "\n",
      "iso_region distinct count: 51 distinct value: ['US-AK', 'US-AL', 'US-AR', 'US-AZ', 'US-CA', 'US-CO', 'US-CT', 'US-DC', 'US-DE', 'US-FL', 'US-GA', 'US-HI', 'US-IA', 'US-ID', 'US-IL', 'US-IN', 'US-KS', 'US-KY', 'US-LA', 'US-MA', 'US-MD', 'US-ME', 'US-MI', 'US-MN', 'US-MO', 'US-MS', 'US-MT', 'US-NC', 'US-ND', 'US-NE', 'US-NH', 'US-NJ', 'US-NM', 'US-NV', 'US-NY', 'US-OH', 'US-OK', 'US-OR', 'US-PA', 'US-RI', 'US-SC', 'US-SD', 'US-TN', 'US-TX', 'US-UT', 'US-VA', 'US-VT', 'US-WA', 'US-WI', 'US-WV', 'US-WY'] \n",
      "\n",
      "iata_code distinct count: 2014 distinct value: ['AAF', 'AAP', 'ABE', 'ABI', 'ABL', 'ABQ', 'ABR', 'ABY', 'ACB', 'ACK', 'ACT', 'ACV', 'ACY', 'ADG', 'ADK', 'ADM', 'ADQ', 'ADR', 'ADS', 'ADT', 'ADW', 'AEL', 'AET', 'AEX', 'AFF', 'AFN', 'AFO', 'AFW', 'AGC', 'AGN', 'AGO', 'AGS', 'AHC', 'AHD', 'AHF', 'AHH', 'AHM', 'AHN', 'AHT', 'AIA', 'AID', 'AIK', 'AIN', 'AIO', 'AIV', 'AIY', 'AIZ', 'AKB', 'AKC', 'AKI', 'AKK', 'AKN', 'AKO', 'AKP', 'ALB', 'ALE', 'ALI', 'ALM', 'ALN', 'ALO', 'ALS', 'ALW', 'ALX', 'ALZ', 'AMA', 'AMK', 'AMN', 'AMW', 'ANB', 'ANC', 'AND', 'ANI', 'ANN', 'ANP', 'ANQ', 'ANV', 'ANW', 'ANY', 'AOH', 'AOO', 'AOS', 'APA', 'APC', 'APF', 'APG', 'APH', 'APN', 'APT', 'APV', 'AQY', 'ARA', 'ARB', 'ARC', 'ARG', 'ART', 'ARV', 'ARX', 'ASE', 'ASH', 'ASL', 'ASN', 'ASQ', 'AST', 'ASX', 'ASY', 'ATE', 'ATK', 'ATL', 'ATO', 'ATS', 'ATT', 'ATU', 'ATW', 'ATY', 'AUG', 'AUK', 'AUM', 'AUN', 'AUO', 'AUS', 'AUW', 'AUZ', 'AVL', 'AVO', 'AVP', 'AVW', 'AVX', 'AWM', 'AXB', 'AXG', 'AXN', 'AXS', 'AXV', 'AXX', 'AYE', 'AYS', 'AYZ', 'AZA', 'AZO', 'BAB', 'BAD', 'BAF', 'BAM', 'BBB', 'BBC', 'BBD', 'BBW', 'BBX', 'BCB', 'BCC', 'BCE', 'BCJ', 'BCS', 'BCT', 'BDE', 'BDF', 'BDG', 'BDL', 'BDR', 'BDX', 'BDY', 'BEC', 'BED', 'BEH', 'BET', 'BFD', 'BFF', 'BFG', 'BFI', 'BFK', 'BFL', 'BFM', 'BFP', 'BFR', 'BFT', 'BGD', 'BGE', 'BGM', 'BGQ', 'BGR', 'BGT', 'BHB', 'BHM', 'BID', 'BIE', 'BIF', 'BIG', 'BIH', 'BIL', 'BIS', 'BIX', 'BJC', 'BJI', 'BJJ', 'BKC', 'BKD', 'BKE', 'BKF', 'BKG', 'BKH'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check soe \n",
    "check_distinct(df_airport_us.dropna(how = 'any', subset = ['iata_code']), ['ident','iso_region','iata_code' ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# split iso_region column to single out State field\n",
    "split_region = f.split(df_airport_us['iso_region'], '-')\n",
    "df_airport_us = df_airport_us.withColumn('state', split_region.getItem(1)) \\\n",
    "                .drop('iso_region') \\\n",
    "                .drop('ident') \\\n",
    "                .withColumnRenamed('municipality', 'city') \\\n",
    "                .withColumnRenamed('iso_country', 'country') \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# split coordinates column\n",
    "split_coordinates = f.split(df_airport_us['coordinates'], ',')\n",
    "df_airport_us = df_airport_us.withColumn('latitude', split_coordinates.getItem(0)) \\\n",
    "                .withColumn('longitude', split_coordinates.getItem(1)) \\\n",
    "                .drop('coordinates') \\\n",
    "                .drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# remove null of iata_code which would be our primary key\n",
    "df_airport_us = df_airport_us.dropna(how = 'any', subset = ['iata_code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row Count 2019\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>elevation_ft</th>\n",
       "      <th>continent</th>\n",
       "      <th>country</th>\n",
       "      <th>city</th>\n",
       "      <th>gps_code</th>\n",
       "      <th>iata_code</th>\n",
       "      <th>local_code</th>\n",
       "      <th>state</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>closed</td>\n",
       "      <td>Ben Bruce Memorial Airpark</td>\n",
       "      <td>44</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>Evadale</td>\n",
       "      <td>4TE8</td>\n",
       "      <td>EVA</td>\n",
       "      <td>4TE8</td>\n",
       "      <td>TX</td>\n",
       "      <td>-94.07350158690001</td>\n",
       "      <td>30.3209991455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>seaplane_base</td>\n",
       "      <td>Yes Bay Lodge Seaplane Base</td>\n",
       "      <td>None</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>Yes Bay</td>\n",
       "      <td>78K</td>\n",
       "      <td>WYB</td>\n",
       "      <td>78K</td>\n",
       "      <td>AK</td>\n",
       "      <td>-131.800994873</td>\n",
       "      <td>55.9163017273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>small_airport</td>\n",
       "      <td>Goodnews Airport</td>\n",
       "      <td>15</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>Goodnews</td>\n",
       "      <td>GNU</td>\n",
       "      <td>GNU</td>\n",
       "      <td>GNU</td>\n",
       "      <td>AK</td>\n",
       "      <td>-161.57699585</td>\n",
       "      <td>59.117401123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>medium_airport</td>\n",
       "      <td>Childress Municipal Airport</td>\n",
       "      <td>1954</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>Childress</td>\n",
       "      <td>KCDS</td>\n",
       "      <td>CDS</td>\n",
       "      <td>CDS</td>\n",
       "      <td>TX</td>\n",
       "      <td>-100.288002014</td>\n",
       "      <td>34.4337997437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>medium_airport</td>\n",
       "      <td>Columbia Regional Airport</td>\n",
       "      <td>889</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>Columbia</td>\n",
       "      <td>KCOU</td>\n",
       "      <td>COU</td>\n",
       "      <td>COU</td>\n",
       "      <td>MO</td>\n",
       "      <td>-92.21959686279297</td>\n",
       "      <td>38.81809997558594</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             type                         name elevation_ft continent country  \\\n",
       "0          closed   Ben Bruce Memorial Airpark           44        NA      US   \n",
       "1   seaplane_base  Yes Bay Lodge Seaplane Base         None        NA      US   \n",
       "2   small_airport             Goodnews Airport           15        NA      US   \n",
       "3  medium_airport  Childress Municipal Airport         1954        NA      US   \n",
       "4  medium_airport    Columbia Regional Airport          889        NA      US   \n",
       "\n",
       "        city gps_code iata_code local_code state            latitude  \\\n",
       "0    Evadale     4TE8       EVA       4TE8    TX  -94.07350158690001   \n",
       "1    Yes Bay      78K       WYB        78K    AK      -131.800994873   \n",
       "2   Goodnews      GNU       GNU        GNU    AK       -161.57699585   \n",
       "3  Childress     KCDS       CDS        CDS    TX      -100.288002014   \n",
       "4   Columbia     KCOU       COU        COU    MO  -92.21959686279297   \n",
       "\n",
       "            longitude  \n",
       "0       30.3209991455  \n",
       "1       55.9163017273  \n",
       "2        59.117401123  \n",
       "3       34.4337997437  \n",
       "4   38.81809997558594  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Row Count', df_airport_us.count())\n",
    "df_airport_us.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "|iata_code|count|\n",
      "+---------+-----+\n",
      "|      CLG|    2|\n",
      "|      AUS|    2|\n",
      "|      AHT|    2|\n",
      "|      ESP|    2|\n",
      "|      PHL|    2|\n",
      "+---------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check what are duplicates\n",
    "df_airport_us.groupBy(['iata_code']) \\\n",
    "    .count() \\\n",
    "    .where(f.col('count') >1) \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------------+------------+---------+-------+----------------+--------+---------+----------+-----+-------------------+-------------------+\n",
      "|         type|                name|elevation_ft|continent|country|            city|gps_code|iata_code|local_code|state|           latitude|          longitude|\n",
      "+-------------+--------------------+------------+---------+-------+----------------+--------+---------+----------+-----+-------------------+-------------------+\n",
      "|       closed|Amchitka Army Air...|         215|       NA|     US| Amchitka Island|    null|      AHT|      null|   AK|      179.259166667|      51.3777777778|\n",
      "|       closed|Amchitka Army Air...|         215|       NA|     US| Amchitka Island|    PAHT|      AHT|      null|   AK|      179.259166667|      51.3777777778|\n",
      "|       closed|Austin Robert Mue...|        null|       NA|     US|            null|    KAUS|      AUS|      null|   TX|     -97.6997852325|      30.2987223546|\n",
      "|large_airport|Austin Bergstrom ...|         542|       NA|     US|          Austin|    KAUS|      AUS|       AUS|   TX|  -97.6698989868164| 30.194499969482422|\n",
      "|small_airport|New Coalinga Muni...|         622|       NA|     US|        Coalinga|    null|      CLG|       C80|   CA|-120.29399871826172|  36.16310119628906|\n",
      "|       closed|    Coalinga Airport|        null|       NA|     US|            null|    null|      CLG|      null|   CA|     -120.360116959|      36.1580433385|\n",
      "|       closed|Birchwood-Pocono ...|         965|       NA|     US|East Stroudsburg|    null|      ESP|      null|   PA|           -75.2521|            41.0643|\n",
      "|small_airport|Stroudsburg Pocon...|         480|       NA|     US|East Stroudsburg|    KN53|      ESP|       N53|   PA|     -75.1605987549|      41.0358009338|\n",
      "|large_airport|Philadelphia Inte...|          36|       NA|     US|    Philadelphia|    KPHL|      PHL|       PHL|   PA| -75.24109649658203|  39.87189865112305|\n",
      "|       closed|         Erase Me 19|        null|       NA|     US|            null|    null|      PHL|      null|   PA|               -0.4|                  0|\n",
      "+-------------+--------------------+------------+---------+-------+----------------+--------+---------+----------+-----+-------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's look into what is causing the duplicate in iata_code\n",
    "in_list = ['CLG', 'AUS', 'AHT', 'ESP', 'PHL']\n",
    "df_airport_us.filter(f.col('iata_code').isin(in_list)) \\\n",
    "            .orderBy(['iata_code']) \\\n",
    "            .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+------------+---------+-------+----+--------+---------+----------+-----+------------------+------------------+\n",
      "|  type|                name|elevation_ft|continent|country|city|gps_code|iata_code|local_code|state|          latitude|         longitude|\n",
      "+------+--------------------+------------+---------+-------+----+--------+---------+----------+-----+------------------+------------------+\n",
      "|closed|       Carmel Valley|        null|       NA|     US|null|    null|      O62|      null|   CA|     -121.72911644|     36.4814843441|\n",
      "|closed|Ft Devens Moore A...|         269|       NA|     US|null|    KAYE|      AYE|      null|   MA|-71.60279846191406| 42.56999969482422|\n",
      "|closed|    Coalinga Airport|        null|       NA|     US|null|    null|      CLG|      null|   CA|    -120.360116959|     36.1580433385|\n",
      "|closed|Austin Robert Mue...|        null|       NA|     US|null|    KAUS|      AUS|      null|   TX|    -97.6997852325|     30.2987223546|\n",
      "|closed|         Erase Me 19|        null|       NA|     US|null|    null|      PHL|      null|   PA|              -0.4|                 0|\n",
      "|closed| Berz-Macomb Airport|         610|       NA|     US|null|    KUIZ|      UIZ|       UIZ|   MI|-82.96540069580078| 42.66389846801758|\n",
      "+------+--------------------+------------+---------+-------+----+--------+---------+----------+-----+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# See null record in city field\n",
    "df_airport_us.filter(f.col('city').isNull()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# drop null in city field if it is one of the duplicate iata_code row\n",
    "df_airport_us = df_airport_us.filter(~(f.col('iata_code').isin(in_list) & f.col('city').isNull()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# drop duplicate in iata_code + city\n",
    "df_airport_us = df_airport_us.drop_duplicates(subset=['iata_code','city'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row Count 2014\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>elevation_ft</th>\n",
       "      <th>continent</th>\n",
       "      <th>country</th>\n",
       "      <th>city</th>\n",
       "      <th>gps_code</th>\n",
       "      <th>iata_code</th>\n",
       "      <th>local_code</th>\n",
       "      <th>state</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>small_airport</td>\n",
       "      <td>Artesia Municipal Airport</td>\n",
       "      <td>3541</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>Artesia</td>\n",
       "      <td>KATS</td>\n",
       "      <td>ATS</td>\n",
       "      <td>ATS</td>\n",
       "      <td>NM</td>\n",
       "      <td>-104.468002319</td>\n",
       "      <td>32.8525009155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>small_airport</td>\n",
       "      <td>Buchanan Field</td>\n",
       "      <td>26</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>Concord</td>\n",
       "      <td>KCCR</td>\n",
       "      <td>CCR</td>\n",
       "      <td>CCR</td>\n",
       "      <td>CA</td>\n",
       "      <td>-122.056999207</td>\n",
       "      <td>37.9897003174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>small_airport</td>\n",
       "      <td>Calexico International Airport</td>\n",
       "      <td>4</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>Calexico</td>\n",
       "      <td>KCXL</td>\n",
       "      <td>CXL</td>\n",
       "      <td>CXL</td>\n",
       "      <td>CA</td>\n",
       "      <td>-115.513000488</td>\n",
       "      <td>32.6694984436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>medium_airport</td>\n",
       "      <td>Bisbee Douglas International Airport</td>\n",
       "      <td>4154</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>Douglas Bisbee</td>\n",
       "      <td>KDUG</td>\n",
       "      <td>DUG</td>\n",
       "      <td>DUG</td>\n",
       "      <td>AZ</td>\n",
       "      <td>-109.603996277</td>\n",
       "      <td>31.4689998627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>small_airport</td>\n",
       "      <td>Danbury Municipal Airport</td>\n",
       "      <td>458</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>Danbury</td>\n",
       "      <td>KDXR</td>\n",
       "      <td>DXR</td>\n",
       "      <td>DXR</td>\n",
       "      <td>CT</td>\n",
       "      <td>-73.48220062259999</td>\n",
       "      <td>41.371498107899995</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             type                                  name elevation_ft  \\\n",
       "0   small_airport             Artesia Municipal Airport         3541   \n",
       "1   small_airport                        Buchanan Field           26   \n",
       "2   small_airport        Calexico International Airport            4   \n",
       "3  medium_airport  Bisbee Douglas International Airport         4154   \n",
       "4   small_airport             Danbury Municipal Airport          458   \n",
       "\n",
       "  continent country            city gps_code iata_code local_code state  \\\n",
       "0        NA      US         Artesia     KATS       ATS        ATS    NM   \n",
       "1        NA      US         Concord     KCCR       CCR        CCR    CA   \n",
       "2        NA      US        Calexico     KCXL       CXL        CXL    CA   \n",
       "3        NA      US  Douglas Bisbee     KDUG       DUG        DUG    AZ   \n",
       "4        NA      US         Danbury     KDXR       DXR        DXR    CT   \n",
       "\n",
       "             latitude            longitude  \n",
       "0      -104.468002319        32.8525009155  \n",
       "1      -122.056999207        37.9897003174  \n",
       "2      -115.513000488        32.6694984436  \n",
       "3      -109.603996277        31.4689998627  \n",
       "4  -73.48220062259999   41.371498107899995  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Row Count', df_airport_us.count())\n",
    "df_airport_us.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "|iata_code|count|\n",
      "+---------+-----+\n",
      "+---------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# final check on duplicate in iata_code => no more duplicate in iata_code\n",
    "df_airport_us.groupBy(['iata_code']) \\\n",
    "    .count() \\\n",
    "    .where(f.col('count') >1) \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Temperature Table Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "City distinct count: 3448 distinct value: ['A Coruña', 'Aachen', 'Aalborg', 'Aba', 'Abadan', 'Abakaliki', 'Abakan', 'Abbotsford', 'Abengourou', 'Abeokuta', 'Aberdeen', 'Abha', 'Abidjan', 'Abiko', 'Abilene', 'Abohar', 'Abomey Calavi', 'Abu Dhabi', 'Abuja', 'Acapulco', 'Acarigua', 'Accra', 'Achalpur', 'Acheng', 'Achinsk', 'Acuña', 'Adana', 'Addis Abeba', 'Adelaide', 'Aden', 'Adilabad', 'Adiwerna', 'Adoni', 'Afyonkarahisar', 'Agadir', 'Agartala', 'Agboville', 'Ageo', 'Agra', 'Aguascalientes', 'Ahmadabad', 'Ahmadnagar', 'Ahmadpur East', 'Ahvaz', 'Aix En Provence', 'Aizawl', 'Ajdabiya', 'Ajmer', 'Akashi', 'Akishima', 'Akita', 'Akola', 'Akron', 'Aksaray', 'Aksu', 'Aktau', 'Akure', 'Akyab', 'Alagoinhas', 'Alandur', 'Alanya', 'Alappuzha', 'Albacete', 'Alberton', 'Albuquerque', 'Albury', 'Alcalá De Henares', 'Alcobendas', 'Alcorcón', 'Aleppo', 'Alexandria', 'Algeciras', 'Algiers', 'Aligarh', 'Allahabad', 'Allentown', 'Almaty', 'Almere', 'Almería', 'Almetyevsk', 'Alor Setar', 'Altay', 'Alwar', 'Amadora', 'Amagasaki', 'Amaigbo', 'Amarillo', 'Ambala', 'Ambarnath', 'Ambato', 'Ambattur', 'Ambon', 'Ambur', 'Americana', 'Amersfoort', 'Amiens', 'Amol', 'Amravati', 'Amritsar', 'Amroha', 'Amsterdam', 'Anaco', 'Anaheim', 'Anand', 'Ananindeua', 'Anantapur', 'Anbu', 'Anchorage', 'Ancona', 'Anda', 'Andijon', 'Angarsk', 'Angeles', 'Angers', 'Angra Dos Reis', 'Angren', 'Anjo', 'Ankang', 'Ankara', 'Ann Arbor', 'Anqing', 'Anqiu', 'Anshan', 'Anshun', 'Antakya', 'Antalya', 'Antananarivo', 'Antioch', 'Antipolo', 'Antofagasta', 'Antsirabe', 'Antwerp', 'Anyama', 'Anyang', 'Anápolis', 'Apeldoorn', 'Apodaca', 'Apopa', 'Apucarana', 'Aqtöbe', 'Ara', 'Aracaju', 'Arad', 'Araguaína', 'Arak', 'Arapiraca', 'Araraquara', 'Araras', 'Araruama', 'Araucária', 'Araçatuba', 'Ardabil', 'Arequipa', 'Arica', 'Arjawinangun', 'Arkhangelsk', 'Arlington', 'Armavir', 'Armenia', 'Arnhem', 'Arusha', 'Arvada', 'Aryanah', 'Arzamas', 'Asahikawa', 'Asaka', 'Asansol', 'Asfi', 'Asgabat', 'Ashdod', 'Ashikaga', 'Ashqelon', 'Asmara', 'Astana', 'Astanajapura', 'Astrakhan', 'Asunción', 'Aswan', 'Asyut', 'Athens', 'Atibaia', 'Atlanta', 'Atsugi', 'Atyrau', 'Auckland', 'Augsburg', 'Aurangabad', 'Aurora', 'Austin', 'Avadi', 'Awassa', 'Awka', 'Ayacucho', 'Ayer Itam', 'Azamgarh', 'Azare', 'Babakan', 'Babol', 'Bac Lieu', 'Bacau'] \n",
      "\n",
      "Country distinct count: 159 distinct value: ['Afghanistan', 'Albania', 'Algeria', 'Angola', 'Argentina', 'Armenia', 'Australia', 'Austria', 'Azerbaijan', 'Bahamas', 'Bahrain', 'Bangladesh', 'Belarus', 'Belgium', 'Benin', 'Bolivia', 'Bosnia And Herzegovina', 'Botswana', 'Brazil', 'Bulgaria', 'Burkina Faso', 'Burma', 'Burundi', 'Cambodia', 'Cameroon', 'Canada', 'Central African Republic', 'Chad', 'Chile', 'China', 'Colombia', 'Congo', 'Congo (Democratic Republic Of The)', 'Costa Rica', 'Croatia', 'Cuba', 'Cyprus', 'Czech Republic', \"Côte D'Ivoire\", 'Denmark', 'Djibouti', 'Dominican Republic', 'Ecuador', 'Egypt', 'El Salvador', 'Equatorial Guinea', 'Eritrea', 'Estonia', 'Ethiopia', 'Finland', 'France', 'Gabon', 'Gambia', 'Georgia', 'Germany', 'Ghana', 'Greece', 'Guatemala', 'Guinea', 'Guinea Bissau', 'Guyana', 'Haiti', 'Honduras', 'Hong Kong', 'Hungary', 'Iceland', 'India', 'Indonesia', 'Iran', 'Iraq', 'Ireland', 'Israel', 'Italy', 'Jamaica', 'Japan', 'Jordan', 'Kazakhstan', 'Kenya', 'Laos', 'Latvia', 'Lebanon', 'Lesotho', 'Liberia', 'Libya', 'Lithuania', 'Macedonia', 'Madagascar', 'Malawi', 'Malaysia', 'Mali', 'Mauritania', 'Mauritius', 'Mexico', 'Moldova', 'Mongolia', 'Montenegro', 'Morocco', 'Mozambique', 'Namibia', 'Nepal', 'Netherlands', 'New Zealand', 'Nicaragua', 'Niger', 'Nigeria', 'Norway', 'Oman', 'Pakistan', 'Panama', 'Papua New Guinea', 'Paraguay', 'Peru', 'Philippines', 'Poland', 'Portugal', 'Puerto Rico', 'Qatar', 'Reunion', 'Romania', 'Russia', 'Rwanda', 'Saudi Arabia', 'Senegal', 'Serbia', 'Sierra Leone', 'Singapore', 'Slovakia', 'Slovenia', 'Somalia', 'South Africa', 'South Korea', 'Spain', 'Sri Lanka', 'Sudan', 'Suriname', 'Swaziland', 'Sweden', 'Switzerland', 'Syria', 'Taiwan', 'Tajikistan', 'Tanzania', 'Thailand', 'Togo', 'Tunisia', 'Turkey', 'Turkmenistan', 'Uganda', 'Ukraine', 'United Arab Emirates', 'United Kingdom', 'United States', 'Uruguay', 'Uzbekistan', 'Venezuela', 'Vietnam', 'Yemen', 'Zambia', 'Zimbabwe'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "check_distinct(df_temp, ['City', 'Country'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row Count 687289\n"
     ]
    }
   ],
   "source": [
    "# Temperature to Limit to only \"United States\" record\n",
    "\n",
    "df_temp_us = df_temp.filter(df_temp['Country'] == 'United States')\n",
    "print('Row Count', df_temp_us.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Split datetime column into year and month\n",
    "\n",
    "df_temp_us = df_temp_us.withColumn('year', f.year(f.col('dt'))) \\\n",
    "            .withColumn('month', f.month(f.col('dt')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "year distinct count: 271 distinct value: [1743, 1744, 1745, 1746, 1747, 1748, 1749, 1750, 1751, 1752, 1753, 1754, 1755, 1756, 1757, 1758, 1759, 1760, 1761, 1762, 1763, 1764, 1765, 1766, 1767, 1768, 1769, 1770, 1771, 1772, 1773, 1774, 1775, 1776, 1777, 1778, 1779, 1780, 1781, 1782, 1783, 1784, 1785, 1786, 1787, 1788, 1789, 1790, 1791, 1792, 1793, 1794, 1795, 1796, 1797, 1798, 1799, 1800, 1801, 1802, 1803, 1804, 1805, 1806, 1807, 1808, 1809, 1810, 1811, 1812, 1813, 1814, 1815, 1816, 1817, 1818, 1819, 1820, 1821, 1822, 1823, 1824, 1825, 1826, 1827, 1828, 1829, 1830, 1831, 1832, 1833, 1834, 1835, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1845, 1846, 1847, 1848, 1849, 1850, 1851, 1852, 1853, 1854, 1855, 1856, 1857, 1858, 1859, 1860, 1861, 1862, 1863, 1864, 1865, 1866, 1867, 1868, 1869, 1870, 1871, 1872, 1873, 1874, 1875, 1876, 1877, 1878, 1879, 1880, 1881, 1882, 1883, 1884, 1885, 1886, 1887, 1888, 1889, 1890, 1891, 1892, 1893, 1894, 1895, 1896, 1897, 1898, 1899, 1900, 1901, 1902, 1903, 1904, 1905, 1906, 1907, 1908, 1909, 1910, 1911, 1912, 1913, 1914, 1915, 1916, 1917, 1918, 1919, 1920, 1921, 1922, 1923, 1924, 1925, 1926, 1927, 1928, 1929, 1930, 1931, 1932, 1933, 1934, 1935, 1936, 1937, 1938, 1939, 1940, 1941, 1942, 1943, 1944, 1945, 1946, 1947, 1948, 1949, 1950, 1951, 1952, 1953, 1954, 1955, 1956, 1957, 1958, 1959, 1960, 1961, 1962, 1963, 1964, 1965, 1966, 1967, 1968, 1969, 1970, 1971, 1972, 1973, 1974, 1975, 1976, 1977, 1978, 1979, 1980, 1981, 1982, 1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013] \n",
      "\n",
      "month distinct count: 12 distinct value: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "check_distinct(df_temp_us, ['year', 'month'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### There are only temperature data until 2013 while the immigration data is in 2016. Let's keep only the 2013 temperature data as it is closet to immigration data time range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row Count 2313\n"
     ]
    }
   ],
   "source": [
    "df_temp_us = df_temp_us.filter(f.col('year') == 2013)\n",
    "print('Row Count', df_temp_us.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Write one function that can show number of null record and its % of total rows.\n",
    "def check_missing_all(df, cols):\n",
    "  \"\"\"\n",
    "  This function to allow quickly specify the dataframe and columns to perform null value count and its % to total row counts, and print out.\n",
    "\n",
    "  Args:\n",
    "      df (object): the spark dataframe to check missing value\n",
    "      cols (list of string): the column name to check missing value\n",
    "  \n",
    "  \"\"\"  \n",
    "      \n",
    "  from pyspark.sql import functions as f\n",
    "  df_copy = df\n",
    "  total_cnt = df_copy.count()\n",
    "  print('Total Row Count', total_cnt)  \n",
    "  type_map = dict(df_copy[cols].dtypes)\n",
    "  for key in type_map:\n",
    "    if type_map[key] == \"timestamp\":\n",
    "      df_copy = df_copy.withColumn(key, f.col(key).cast(StringType()))\n",
    "    col_cnt = df_copy.filter(df_copy[key].isNull() | f.isnan(df_copy[key]) | (df_copy[key] == \"\") ).count()\n",
    "    print(key, \"with null values\", \"%15s\" % col_cnt,  \"%15s\" % round(col_cnt / total_cnt * 100,2),\"%\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Row Count 2313\n",
      "dt with null values               0             0.0 %\n",
      "AverageTemperature with null values               1            0.04 %\n",
      "AverageTemperatureUncertainty with null values               1            0.04 %\n",
      "City with null values               0             0.0 %\n",
      "Country with null values               0             0.0 %\n",
      "Latitude with null values               0             0.0 %\n",
      "Longitude with null values               0             0.0 %\n",
      "year with null values               0             0.0 %\n",
      "month with null values               0             0.0 %\n"
     ]
    }
   ],
   "source": [
    "check_missing_all(df_temp_us, df_temp_us.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Let's drop the null and duplicates\n",
    "\n",
    "df_temp_us = df_temp_us.dropna(how = 'any') \\\n",
    "                .drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Select only the key fields and aggregate the temperature fields by taking the mean.\n",
    "cols_to_avg = ['AverageTemperature', 'AverageTemperatureUncertainty']\n",
    "exprs = {x: \"mean\" for x in cols_to_avg}\n",
    "df_temp_us_avg = df_temp_us.groupby(['City', 'year', 'month']).agg(exprs) \\\n",
    "                .withColumnRenamed('avg(AverageTemperature)', 'Avg_Temperature') \\\n",
    "                .withColumnRenamed('avg(AverageTemperatureUncertainty)', 'Avg_Temperature_Uncertainty')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row Count 2231\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>Avg_Temperature</th>\n",
       "      <th>Avg_Temperature_Uncertainty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bakersfield</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>6.501</td>\n",
       "      <td>0.425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Westminster</td>\n",
       "      <td>2013</td>\n",
       "      <td>5</td>\n",
       "      <td>13.409</td>\n",
       "      <td>0.368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>East Los Angeles</td>\n",
       "      <td>2013</td>\n",
       "      <td>5</td>\n",
       "      <td>19.028</td>\n",
       "      <td>0.531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Topeka</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.162</td>\n",
       "      <td>0.410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Worcester</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.367</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               City  year  month  Avg_Temperature  Avg_Temperature_Uncertainty\n",
       "0       Bakersfield  2013      1            6.501                        0.425\n",
       "1       Westminster  2013      5           13.409                        0.368\n",
       "2  East Los Angeles  2013      5           19.028                        0.531\n",
       "3            Topeka  2013      1           -0.162                        0.410\n",
       "4         Worcester  2013      3            0.699                        0.367"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Row Count', df_temp_us_avg.count())\n",
    "df_temp_us_avg.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Demographic Table Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Number of Veterans</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>Average Household Size</th>\n",
       "      <th>State Code</th>\n",
       "      <th>Race</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Silver Spring</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>33.8</td>\n",
       "      <td>40601</td>\n",
       "      <td>41862</td>\n",
       "      <td>82463</td>\n",
       "      <td>1562</td>\n",
       "      <td>30908</td>\n",
       "      <td>2.6</td>\n",
       "      <td>MD</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>25924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quincy</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>41.0</td>\n",
       "      <td>44129</td>\n",
       "      <td>49500</td>\n",
       "      <td>93629</td>\n",
       "      <td>4147</td>\n",
       "      <td>32935</td>\n",
       "      <td>2.39</td>\n",
       "      <td>MA</td>\n",
       "      <td>White</td>\n",
       "      <td>58723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hoover</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>38.5</td>\n",
       "      <td>38040</td>\n",
       "      <td>46799</td>\n",
       "      <td>84839</td>\n",
       "      <td>4819</td>\n",
       "      <td>8229</td>\n",
       "      <td>2.58</td>\n",
       "      <td>AL</td>\n",
       "      <td>Asian</td>\n",
       "      <td>4759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rancho Cucamonga</td>\n",
       "      <td>California</td>\n",
       "      <td>34.5</td>\n",
       "      <td>88127</td>\n",
       "      <td>87105</td>\n",
       "      <td>175232</td>\n",
       "      <td>5821</td>\n",
       "      <td>33878</td>\n",
       "      <td>3.18</td>\n",
       "      <td>CA</td>\n",
       "      <td>Black or African-American</td>\n",
       "      <td>24437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Newark</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>34.6</td>\n",
       "      <td>138040</td>\n",
       "      <td>143873</td>\n",
       "      <td>281913</td>\n",
       "      <td>5829</td>\n",
       "      <td>86253</td>\n",
       "      <td>2.73</td>\n",
       "      <td>NJ</td>\n",
       "      <td>White</td>\n",
       "      <td>76402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               City          State Median Age Male Population  \\\n",
       "0     Silver Spring       Maryland       33.8           40601   \n",
       "1            Quincy  Massachusetts       41.0           44129   \n",
       "2            Hoover        Alabama       38.5           38040   \n",
       "3  Rancho Cucamonga     California       34.5           88127   \n",
       "4            Newark     New Jersey       34.6          138040   \n",
       "\n",
       "  Female Population Total Population Number of Veterans Foreign-born  \\\n",
       "0             41862            82463               1562        30908   \n",
       "1             49500            93629               4147        32935   \n",
       "2             46799            84839               4819         8229   \n",
       "3             87105           175232               5821        33878   \n",
       "4            143873           281913               5829        86253   \n",
       "\n",
       "  Average Household Size State Code                       Race  Count  \n",
       "0                    2.6         MD         Hispanic or Latino  25924  \n",
       "1                   2.39         MA                      White  58723  \n",
       "2                   2.58         AL                      Asian   4759  \n",
       "3                   3.18         CA  Black or African-American  24437  \n",
       "4                   2.73         NJ                      White  76402  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_demo.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# drop State field and use State Code instead since we will have one dimension table for state name\n",
    "df_demo = df_demo.drop('State')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Number of Veterans</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>Average Household Size</th>\n",
       "      <th>State Code</th>\n",
       "      <th>Race</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Silver Spring</td>\n",
       "      <td>33.8</td>\n",
       "      <td>40601</td>\n",
       "      <td>41862</td>\n",
       "      <td>82463</td>\n",
       "      <td>1562</td>\n",
       "      <td>30908</td>\n",
       "      <td>2.6</td>\n",
       "      <td>MD</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>25924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quincy</td>\n",
       "      <td>41.0</td>\n",
       "      <td>44129</td>\n",
       "      <td>49500</td>\n",
       "      <td>93629</td>\n",
       "      <td>4147</td>\n",
       "      <td>32935</td>\n",
       "      <td>2.39</td>\n",
       "      <td>MA</td>\n",
       "      <td>White</td>\n",
       "      <td>58723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hoover</td>\n",
       "      <td>38.5</td>\n",
       "      <td>38040</td>\n",
       "      <td>46799</td>\n",
       "      <td>84839</td>\n",
       "      <td>4819</td>\n",
       "      <td>8229</td>\n",
       "      <td>2.58</td>\n",
       "      <td>AL</td>\n",
       "      <td>Asian</td>\n",
       "      <td>4759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rancho Cucamonga</td>\n",
       "      <td>34.5</td>\n",
       "      <td>88127</td>\n",
       "      <td>87105</td>\n",
       "      <td>175232</td>\n",
       "      <td>5821</td>\n",
       "      <td>33878</td>\n",
       "      <td>3.18</td>\n",
       "      <td>CA</td>\n",
       "      <td>Black or African-American</td>\n",
       "      <td>24437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Newark</td>\n",
       "      <td>34.6</td>\n",
       "      <td>138040</td>\n",
       "      <td>143873</td>\n",
       "      <td>281913</td>\n",
       "      <td>5829</td>\n",
       "      <td>86253</td>\n",
       "      <td>2.73</td>\n",
       "      <td>NJ</td>\n",
       "      <td>White</td>\n",
       "      <td>76402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               City Median Age Male Population Female Population  \\\n",
       "0     Silver Spring       33.8           40601             41862   \n",
       "1            Quincy       41.0           44129             49500   \n",
       "2            Hoover       38.5           38040             46799   \n",
       "3  Rancho Cucamonga       34.5           88127             87105   \n",
       "4            Newark       34.6          138040            143873   \n",
       "\n",
       "  Total Population Number of Veterans Foreign-born Average Household Size  \\\n",
       "0            82463               1562        30908                    2.6   \n",
       "1            93629               4147        32935                   2.39   \n",
       "2            84839               4819         8229                   2.58   \n",
       "3           175232               5821        33878                   3.18   \n",
       "4           281913               5829        86253                   2.73   \n",
       "\n",
       "  State Code                       Race  Count  \n",
       "0         MD         Hispanic or Latino  25924  \n",
       "1         MA                      White  58723  \n",
       "2         AL                      Asian   4759  \n",
       "3         CA  Black or African-American  24437  \n",
       "4         NJ                      White  76402  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_demo.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|sum(count)|\n",
      "+----------+\n",
      "|      2889|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check whethere there are duplicate city and state\n",
    "df_demo.groupBy(['City', 'State Code']) \\\n",
    "    .count() \\\n",
    "    .where(f.col('count') >1) \\\n",
    "    .select(f.sum('count')) \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+---------------+-----------------+----------------+------------------+------------+----------------------+----------+--------------------+------+\n",
      "|   City|Median Age|Male Population|Female Population|Total Population|Number of Veterans|Foreign-born|Average Household Size|State Code|                Race| Count|\n",
      "+-------+----------+---------------+-----------------+----------------+------------------+------------+----------------------+----------+--------------------+------+\n",
      "|Abilene|      31.3|          65212|            60664|          125876|              9367|        8129|                  2.64|        TX|               White| 95487|\n",
      "|Abilene|      31.3|          65212|            60664|          125876|              9367|        8129|                  2.64|        TX|American Indian a...|  1813|\n",
      "|Abilene|      31.3|          65212|            60664|          125876|              9367|        8129|                  2.64|        TX|               Asian|  2929|\n",
      "|Abilene|      31.3|          65212|            60664|          125876|              9367|        8129|                  2.64|        TX|  Hispanic or Latino| 33222|\n",
      "|Abilene|      31.3|          65212|            60664|          125876|              9367|        8129|                  2.64|        TX|Black or African-...| 14449|\n",
      "|  Akron|      38.1|          96886|           100667|          197553|             12878|       10024|                  2.24|        OH|Black or African-...| 66551|\n",
      "|  Akron|      38.1|          96886|           100667|          197553|             12878|       10024|                  2.24|        OH|American Indian a...|  1845|\n",
      "|  Akron|      38.1|          96886|           100667|          197553|             12878|       10024|                  2.24|        OH|               White|129192|\n",
      "|  Akron|      38.1|          96886|           100667|          197553|             12878|       10024|                  2.24|        OH|               Asian|  9033|\n",
      "|  Akron|      38.1|          96886|           100667|          197553|             12878|       10024|                  2.24|        OH|  Hispanic or Latino|  3684|\n",
      "+-------+----------+---------------+-----------------+----------------+------------------+------------+----------------------+----------+--------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# To sort to visually inspect what is causing the duplicate => Race field\n",
    "cols_sort = ['City','State Code']\n",
    "df_demo.orderBy(cols_sort, ascending = True).limit(10).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Number of Veterans</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>Average Household Size</th>\n",
       "      <th>State Code</th>\n",
       "      <th>American Indian and Alaska Native</th>\n",
       "      <th>Asian</th>\n",
       "      <th>Black or African-American</th>\n",
       "      <th>Hispanic or Latino</th>\n",
       "      <th>White</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kalamazoo</td>\n",
       "      <td>26.4</td>\n",
       "      <td>37175</td>\n",
       "      <td>38865</td>\n",
       "      <td>76040</td>\n",
       "      <td>3048</td>\n",
       "      <td>3482</td>\n",
       "      <td>2.36</td>\n",
       "      <td>MI</td>\n",
       "      <td>954.0</td>\n",
       "      <td>2429.0</td>\n",
       "      <td>19194.0</td>\n",
       "      <td>4114.0</td>\n",
       "      <td>56866.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Augusta-Richmond County consolidated government</td>\n",
       "      <td>33.7</td>\n",
       "      <td>94662</td>\n",
       "      <td>101917</td>\n",
       "      <td>196579</td>\n",
       "      <td>19085</td>\n",
       "      <td>7915</td>\n",
       "      <td>2.67</td>\n",
       "      <td>GA</td>\n",
       "      <td>1667.0</td>\n",
       "      <td>4429.0</td>\n",
       "      <td>112271.0</td>\n",
       "      <td>9068.0</td>\n",
       "      <td>77940.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Weston</td>\n",
       "      <td>38.6</td>\n",
       "      <td>32956</td>\n",
       "      <td>36991</td>\n",
       "      <td>69947</td>\n",
       "      <td>1507</td>\n",
       "      <td>30876</td>\n",
       "      <td>3.34</td>\n",
       "      <td>FL</td>\n",
       "      <td>128.0</td>\n",
       "      <td>4130.0</td>\n",
       "      <td>3697.0</td>\n",
       "      <td>36687.0</td>\n",
       "      <td>61021.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jacksonville</td>\n",
       "      <td>24.2</td>\n",
       "      <td>40015</td>\n",
       "      <td>27348</td>\n",
       "      <td>67363</td>\n",
       "      <td>8252</td>\n",
       "      <td>3732</td>\n",
       "      <td>2.51</td>\n",
       "      <td>NC</td>\n",
       "      <td>1741.0</td>\n",
       "      <td>4204.0</td>\n",
       "      <td>13253.0</td>\n",
       "      <td>11947.0</td>\n",
       "      <td>51245.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>New Rochelle</td>\n",
       "      <td>40.6</td>\n",
       "      <td>38871</td>\n",
       "      <td>40967</td>\n",
       "      <td>79838</td>\n",
       "      <td>2780</td>\n",
       "      <td>26960</td>\n",
       "      <td>2.85</td>\n",
       "      <td>NY</td>\n",
       "      <td>645.0</td>\n",
       "      <td>4218.0</td>\n",
       "      <td>17723.0</td>\n",
       "      <td>23548.0</td>\n",
       "      <td>44435.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              City Median Age Male Population  \\\n",
       "0                                        Kalamazoo       26.4           37175   \n",
       "1  Augusta-Richmond County consolidated government       33.7           94662   \n",
       "2                                           Weston       38.6           32956   \n",
       "3                                     Jacksonville       24.2           40015   \n",
       "4                                     New Rochelle       40.6           38871   \n",
       "\n",
       "  Female Population Total Population Number of Veterans Foreign-born  \\\n",
       "0             38865            76040               3048         3482   \n",
       "1            101917           196579              19085         7915   \n",
       "2             36991            69947               1507        30876   \n",
       "3             27348            67363               8252         3732   \n",
       "4             40967            79838               2780        26960   \n",
       "\n",
       "  Average Household Size State Code  American Indian and Alaska Native  \\\n",
       "0                   2.36         MI                              954.0   \n",
       "1                   2.67         GA                             1667.0   \n",
       "2                   3.34         FL                              128.0   \n",
       "3                   2.51         NC                             1741.0   \n",
       "4                   2.85         NY                              645.0   \n",
       "\n",
       "    Asian  Black or African-American  Hispanic or Latino    White  \n",
       "0  2429.0                    19194.0              4114.0  56866.0  \n",
       "1  4429.0                   112271.0              9068.0  77940.0  \n",
       "2  4130.0                     3697.0             36687.0  61021.0  \n",
       "3  4204.0                    13253.0             11947.0  51245.0  \n",
       "4  4218.0                    17723.0             23548.0  44435.0  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let me pivot the \"Race\" field to make it to multiple columns, in order to keep state code and city to be unique identifier for this table.\n",
    "df_demo = df_demo.groupBy(['City', 'Median Age', 'Male Population', 'Female Population', 'Total Population', 'Number of Veterans', 'Foreign-born', 'Average Household Size', 'State Code']) \\\n",
    "        .pivot('Race') \\\n",
    "        .agg({'Count':'sum'})\n",
    "\n",
    "df_demo.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['City',\n",
       " 'Median Age',\n",
       " 'Male Population',\n",
       " 'Female Population',\n",
       " 'Total Population',\n",
       " 'Number of Veterans',\n",
       " 'Foreign-born',\n",
       " 'Average Household Size',\n",
       " 'State Code',\n",
       " 'American Indian and Alaska Native',\n",
       " 'Asian',\n",
       " 'Black or African-American',\n",
       " 'Hispanic or Latino',\n",
       " 'White']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_demo.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+-----+\n",
      "|City|State Code|count|\n",
      "+----+----------+-----+\n",
      "+----+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Nice, now we can uniquely identify the demographic table by city & state code\n",
    "df_demo.groupBy(['City', 'State Code']) \\\n",
    "    .count() \\\n",
    "    .where(f.col('count') >1) \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Immigration Table Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i94yr distinct count: 1 distinct value: [2016.0] \n",
      "\n",
      "i94mon distinct count: 1 distinct value: [4.0] \n",
      "\n",
      "i94port distinct count: 299 distinct value: ['5KE', '5T6', 'ABG', 'ABQ', 'ABS', 'ADS', 'ADT', 'ADW', 'AGA', 'AGN', 'ALC', 'ANA', 'ANC', 'AND', 'ANZ', 'APF', 'ATL', 'ATW', 'AUS', 'AXB', 'BAL', 'BAU', 'BDL', 'BEB', 'BED', 'BEE', 'BEL', 'BGM', 'BHX', 'BLA', 'BOA', 'BOS', 'BQN', 'BRG', 'BRO', 'BTN', 'BUF', 'BWA', 'BWM', 'CAE', 'CAL', 'CHA', 'CHI', 'CHL', 'CHM', 'CHR', 'CHS', 'CHT', 'CIN', 'CLE', 'CLG', 'CLM', 'CLS', 'CLT', 'CNA', 'CNC', 'COB', 'COL', 'COO', 'CPX', 'CRP', 'CRQ', 'CRY', 'DAB', 'DAC', 'DAL', 'DEN', 'DER', 'DET', 'DLB', 'DLR', 'DNA', 'DNS', 'DOU', 'DPA', 'DUB', 'DVL', 'EDA', 'EGP', 'ELP', 'EPI', 'ERC', 'FAL', 'FAR', 'FCA', 'FER', 'FMY', 'FOK', 'FPR', 'FPT', 'FRB', 'FRE', 'FRI', 'FRT', 'FTC', 'FTF', 'FTK', 'FTL', 'FWA', 'GAL', 'GPM', 'GSP', 'HAL', 'HAM', 'HAR', 'HEF', 'HEL', 'HHW', 'HID', 'HIG', 'HNN', 'HNS', 'HOU', 'HPN', 'HSV', 'HTM', 'HVR', 'ICT', 'INP', 'INT', 'JAC', 'JFA', 'JKM', 'JMZ', 'KAN', 'KEY', 'KOA', 'LAN', 'LAR', 'LAU', 'LCB', 'LEW', 'LEX', 'LIH', 'LLB', 'LNB', 'LOI', 'LOS', 'LOU', 'LUB', 'LUK', 'LVG', 'LWT', 'LYN', 'MAA', 'MAD', 'MAF', 'MAI', 'MAS', 'MCA', 'MDT', 'MEM', 'MET', 'MGM', 'MHT', 'MIA', 'MIL', 'MLB', 'MMU', 'MND', 'MOB', 'MON', 'MOO', 'MOR', 'MRC', 'MTH', 'MWH', 'MYR', 'NAC', 'NAS', 'NC8', 'NCA', 'NEC', 'NEW', 'NIA', 'NIG', 'NOG', 'NOL', 'NOO', 'NOR', 'NRG', 'NRN', 'NRT', 'NSV', 'NYC', 'NYL', 'OAK', 'OGD', 'OGG', 'OMA', 'ONT', 'OPF', 'ORL', 'ORO', 'OTM', 'OTT', 'PAR', 'PBB', 'PCF', 'PDN'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "check_distinct(df_spark_select, ['i94yr', 'i94mon','i94port'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Select only necessary fields\n",
    "immigration_select = ['cicid',\n",
    " 'i94yr',\n",
    " 'i94mon',\n",
    " 'i94cit',\n",
    " 'i94res',\n",
    " 'i94port',\n",
    " 'arrdate',\n",
    " 'i94mode',\n",
    " 'i94addr',\n",
    " 'depdate',\n",
    " 'i94bir',\n",
    " 'i94visa',\n",
    " 'occup',\n",
    " 'biryear',\n",
    " 'gender',\n",
    " 'airline',\n",
    " 'visatype']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_spark_select = df_spark.select(immigration_select)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|cicid|count|\n",
      "+-----+-----+\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check if duplicate in cicid, the primary key field\n",
    "df_spark_select.groupBy(['cicid']) \\\n",
    "    .count() \\\n",
    "    .where(f.col('count') >1) \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "spark.conf.set( \"spark.sql.crossJoin.enabled\" , \"true\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# join in city field from airport table. City field is to be one of the foreign key to temperature and demographic table\n",
    "\n",
    "df_spark_select = df_spark_select.join(df_airport_us.select(['city', 'iata_code']), [df_spark_select.i94port == df_airport_us.iata_code], how='left') \\\n",
    "                    .drop('iata_code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# write a function to rename multiple columns (reference: https://stackoverflow.com/questions/38798567/pyspark-rename-more-than-one-column-using-withcolumnrenamed)\n",
    "\n",
    "def rename_columns(df, columns):\n",
    "    \"\"\"\n",
    "    This function to allow quickly specify the dataframe and its columns for renaming.\n",
    "    \n",
    "    Args:\n",
    "        df (object): the Spark dataframe to rename\n",
    "        columns (dict): a dictinoary containing key value pairs which is old name and new name\n",
    "    \n",
    "    Return:\n",
    "        df (object): the renamed Spark dataframe\n",
    "    \"\"\"\n",
    "       \n",
    "    if isinstance(columns, dict):\n",
    "        for old_name, new_name in columns.items():\n",
    "            df = df.withColumnRenamed(old_name, new_name)\n",
    "        return df\n",
    "    else:\n",
    "        raise ValueError(\"'columns' should be a dict, like {'old_name_1':'new_name_1', 'old_name_2':'new_name_2'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "renamed_dict = {'cicid': 'id', 'i94yr':'year', 'i94mon':'month', 'i94cit':'citizenship', 'i94res':'residence', 'i94port':'airport_code', 'arrdate':'arrival_date', 'i94mode':'travel_mode', 'i94addr':'state_abbr', 'depdate':'departure_date', 'i94bir':'age','i94visa': 'visa_category', 'occup':'occupation', 'biryear':'birth_year' }\n",
    "df_spark_select = rename_columns(df_spark_select, renamed_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 3: Define the Data Model\n",
    "#### 3.1 Conceptual Data Model\n",
    "\n",
    "The design the data model with star schema to make it quick to join tables and perform analysis. The schema of tables is as follows.\n",
    "\n",
    "**Fact Table:**\n",
    "1. immigration_record:\n",
    "          id (PK)\n",
    "          year (FK)\n",
    "          month (FK)\n",
    "          citizenship\n",
    "          residence (FK)\n",
    "          airport_code (FK)\n",
    "          arrival_date\n",
    "          travel_mode (FK)\n",
    "          state_abbr (FK)\n",
    "          city (FK)\n",
    "          departure_date\n",
    "          age\n",
    "          visa_category (FK)\n",
    "          occupation\n",
    "          birth_year\n",
    "          gender\n",
    "          airline\n",
    "          visatype\n",
    "          \n",
    " \n",
    "**Dimension Table:**\n",
    "\n",
    "2. temperature:\n",
    "        City (Composite PK)\n",
    "        year (Composite PK)\n",
    "        month (Composite PK)\n",
    "        Avg_Temperature\n",
    "        Avg_Temperature_Uncertainty\n",
    "\n",
    "3. demographic:\n",
    "        State Code (Composite PK)\n",
    "        City (Composite PK)\n",
    "        Median Age\n",
    "        Male Population\n",
    "        Female Population\n",
    "        Total Population\n",
    "        Number of Veterans\n",
    "        Foreign-born\n",
    "        Average Household Size\n",
    "        American Indian and Alaska Native\n",
    "        Asian\n",
    "        Black or African-American\n",
    "        Hispanic or Latino\n",
    "        White\n",
    "\n",
    "4. airport:\n",
    "        iata_code (PK)\n",
    "        type\n",
    "        name\n",
    "        elevation_ft\n",
    "        continent\n",
    "        country\n",
    "        state\n",
    "        city\n",
    "        local_code\n",
    "        gps_code\n",
    "        latitude\n",
    "        longitude\n",
    "\n",
    "5. immigrant_nationality:\n",
    "        code (PK)\n",
    "        country\n",
    "\n",
    "6. visa_table:\n",
    "        visa_code (PK)\n",
    "        visa_type     \n",
    "\n",
    "7. mode_table:\n",
    "        mode_code (PK)\n",
    "        mode_desc\n",
    "\n",
    "8. state_table:\n",
    "        state_abbr (PK)\n",
    "        state_name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 3.2 Mapping Out Data Pipelines\n",
    "List the steps necessary to pipeline the data into the chosen data model\n",
    "\n",
    "1. Retrive airport data from csv file and do necessary data cleanining to get this dimension table.\n",
    "2. Retrieve immigration and travel data from the sas file, join the immigration table with airport table, and perform necessary data cleaning to get our fact table.\n",
    "3. Retrieve the temperarture data from csv file and perform necessary data cleaning to get this dimension table.\n",
    "4. Retrieve the demographics data from csv file and perform necessary data cleaning to get this dimension table.\n",
    "5. Retrive the travel nationality, mode, state, and visa from the csv file to get these dimension tables.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n",
    "#### 4.1 Create the data model\n",
    "Build the data pipelines to create the data model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def process_airport(file_name ):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function to perform ETL of airport data and return the processed dimension table\n",
    "    \n",
    "    Args:\n",
    "        file_name (string): the filenmame of the airport source file.\n",
    "    \n",
    "    Return:\n",
    "        df_airport_us: the processed Spark dataframe.        \n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    # load in airport file\n",
    "    df_airport =spark.read.format('csv').option('header', 'true').load(file_name)\n",
    "    \n",
    "    # filter to only US airport\n",
    "    df_airport_us = df_airport.filter(df_airport['iso_Country'] == 'US')\n",
    "    \n",
    "    # split iso_region column to single out State field\n",
    "    split_region = f.split(df_airport_us['iso_region'], '-')\n",
    "    df_airport_us = df_airport_us.withColumn('state', split_region.getItem(1)) \\\n",
    "                    .drop('iso_region') \\\n",
    "                    .drop('ident') \\\n",
    "                    .withColumnRenamed('municipality', 'city') \\\n",
    "                    .withColumnRenamed('iso_country', 'country')\n",
    "    \n",
    "    # split coordinates column\n",
    "    split_coordinates = f.split(df_airport_us['coordinates'], ',')\n",
    "    df_airport_us = df_airport_us.withColumn('latitude', split_coordinates.getItem(0)) \\\n",
    "                    .withColumn('longitude', split_coordinates.getItem(1)) \\\n",
    "                    .drop('coordinates') \\\n",
    "                    .drop_duplicates()\n",
    "    \n",
    "    # remove null of iata_code which would be our primary key\n",
    "    df_airport_us = df_airport_us.dropna(how = 'any', subset = ['iata_code'])\n",
    "    \n",
    "    # drop null in city field if it is one of the duplicate iata_code row\n",
    "    in_list = ['CLG', 'AUS', 'AHT', 'ESP', 'PHL']\n",
    "    df_airport_us = df_airport_us.filter(~(f.col('iata_code').isin(in_list) & f.col('city').isNull()) )\n",
    "    \n",
    "    # drop duplicate in iata_code + city\n",
    "    df_airport_us = df_airport_us.drop_duplicates(subset=['iata_code','city'])\n",
    "    \n",
    "    return df_airport_us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def process_immigration(file_name, df_airport_us, package = 'com.github.saurfang.sas.spark'):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function to perform ETL of immigration/travel data and return the processed fact table\n",
    "    \n",
    "    Args:\n",
    "        package: the required package to process the sas file.\n",
    "        file_name (string): the filenmame of the immigration/travel source file.\n",
    "    \n",
    "    Return:\n",
    "        df_spark_select: the processed Spark dataframe.        \n",
    "    \n",
    "    \"\"\"\n",
    "        \n",
    "    from pyspark.sql import SparkSession\n",
    "    \n",
    "    # load necessary package to process sas\n",
    "    spark = SparkSession.builder.\\\n",
    "    config(\"spark.jars.packages\",\"saurfang:spark-sas7bdat:2.0.0-s_2.11\")\\\n",
    "    .enableHiveSupport().getOrCreate()\n",
    "    \n",
    "    #### Import immigration data\n",
    "    df_spark =spark.read.format(package).load(file_name)\n",
    "    \n",
    "    # Select only necessary fields\n",
    "    immigration_select = ['cicid',\n",
    "     'i94yr',\n",
    "     'i94mon',\n",
    "     'i94cit',\n",
    "     'i94res',\n",
    "     'i94port',\n",
    "     'arrdate',\n",
    "     'i94mode',\n",
    "     'i94addr',\n",
    "     'depdate',\n",
    "     'i94bir',\n",
    "     'i94visa',\n",
    "     'occup',\n",
    "     'biryear',\n",
    "     'gender',\n",
    "     'airline',\n",
    "     'visatype']\n",
    "    \n",
    "    df_spark_select = df_spark.select(immigration_select)\n",
    "    \n",
    "    # join in city field from airport table. City field is to be one of the foreign key to temperature and demographic table\n",
    "    spark.conf.set( \"spark.sql.crossJoin.enabled\" , \"true\" )\n",
    "    df_spark_select = df_spark_select.join(df_airport_us.select(['city', 'iata_code']), [df_spark_select.i94port == df_airport_us.iata_code], how='left') \\\n",
    "                    .drop('iata_code')\n",
    "    \n",
    "    # rename the column\n",
    "    renamed_dict = {'cicid': 'id', 'i94yr':'year', 'i94mon':'month', 'i94cit':'citizenship', 'i94res':'residence', 'i94port':'airport_code', 'arrdate':'arrival_date', 'i94mode':'travel_mode', 'i94addr':'state_abbr', 'depdate':'departure_date', 'i94bir':'age','i94visa': 'visa_category', 'occup':'occupation', 'biryear':'birth_year' }\n",
    "    for old_name, new_name in renamed_dict.items():\n",
    "        df_spark_select = df_spark_select.withColumnRenamed(old_name, new_name)\n",
    "            \n",
    "    return df_spark_select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def process_temperature(path_temp):\n",
    "    \"\"\"\n",
    "    This function to perform ETL of temperature data and return the processed dimension table\n",
    "    \n",
    "    Args:\n",
    "        path_temp (string): the filenmame of the temperature source file.\n",
    "    \n",
    "    Return:\n",
    "        df_temp_us_avg (object): the processed Spark dataframe.            \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    path_temp = \"../../data2/GlobalLandTemperaturesByCity.csv\"\n",
    "    df_temp =spark.read.format('csv').option('header', 'true').option('delimiter', ',').load(path_temp)\n",
    "    \n",
    "    # Temperature to Limit to only \"United States\" record\n",
    "    df_temp_us = df_temp.filter(df_temp['Country'] == 'United States')\n",
    "    \n",
    "    # Split datetime column into year and month\n",
    "    df_temp_us = df_temp_us.withColumn('year', f.year(f.col('dt'))) \\\n",
    "                .withColumn('month', f.month(f.col('dt')))\n",
    "    \n",
    "    # filter to year 2013\n",
    "    df_temp_us = df_temp_us.filter(f.col('year') == 2013)\n",
    "    \n",
    "    # Let's drop the null and duplicates\n",
    "    df_temp_us = df_temp_us.dropna(how = 'any') \\\n",
    "                    .drop_duplicates()\n",
    "    \n",
    "    # Select only the key fields and aggregate the temperature fields by taking the mean.\n",
    "    cols_to_avg = ['AverageTemperature', 'AverageTemperatureUncertainty']\n",
    "    exprs = {x: \"mean\" for x in cols_to_avg}\n",
    "    df_temp_us_avg = df_temp_us.groupby(['City', 'year', 'month']).agg(exprs) \\\n",
    "                    .withColumnRenamed('avg(AverageTemperature)', 'Avg_Temperature') \\\n",
    "                    .withColumnRenamed('avg(AverageTemperatureUncertainty)', 'Avg_Temperature_Uncertainty')\n",
    "    \n",
    "    return df_temp_us_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def process_demo(filename):\n",
    "    \"\"\"\n",
    "    This function to perform ETL of demographic data and return the processed dimension table\n",
    "    \n",
    "    Args:\n",
    "        filename (string): the filenmame of the demographic source file.\n",
    "    \n",
    "    Return:\n",
    "        df_demo (object): the processed Spark dataframe.            \n",
    "    \"\"\"    \n",
    "    # load file\n",
    "    df_demo =spark.read.format('csv').option('header', 'true').option('delimiter', ';').load(filename)\n",
    "    \n",
    "    # drop State field\n",
    "    df_demo = df_demo.drop('State')\n",
    "    \n",
    "    # Pivot the Race column into multiple columns to make State Code and City unique identifier\n",
    "    df_demo = df_demo.groupBy(['City', 'Median Age', 'Male Population', 'Female Population', 'Total Population', 'Number of Veterans', 'Foreign-born', 'Average Household Size', 'State Code']) \\\n",
    "        .pivot('Race') \\\n",
    "        .agg({'Count':'sum'})\n",
    "    \n",
    "    # rename the column so no more space that could cause save to parquet problem later on\n",
    "    renamed_dict = {'Median Age':'median_age', 'Male Population':'male_population', 'Female Population':'female_population', 'Total Population':'total_population', 'Number of Veterans':'number_of_veterans', 'Average Household Size':'average_household_size','State Code':'state_code', 'American Indian and Alaska Native':'American_Indian_and_Alaska_Native','Black or African-American':'Black_or_African-American','Hispanic or Latino':'Hispanic_or_Latino'}\n",
    "    for old_name, new_name in renamed_dict.items():\n",
    "        df_demo = df_demo.withColumnRenamed(old_name, new_name)    \n",
    "    \n",
    "    return df_demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Now run these functions to create the tables\n",
    "airport = process_airport('airport-codes_csv.csv')\n",
    "immigration_record = process_immigration(df_airport_us = airport, file_name = '../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat')\n",
    "temperature = process_temperature('../../data2/GlobalLandTemperaturesByCity.csv')\n",
    "demographic = process_demo('us-cities-demographics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Load the remaining tables from csv files that derived from I94_SAS_Labels_Descriptions\n",
    "immigrant_nationality = spark.read.format('csv').option('header', 'true').load('immigration_nationality.csv')\n",
    "state_table = spark.read.format('csv').option('header', 'true').load('state.csv')\n",
    "mode_table = spark.read.format('csv').option('header', 'true').load('mode.csv')\n",
    "visa_table = spark.read.format('csv').option('header', 'true').load('visa.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# write to parquet files for easier querying later\n",
    "immigration_record.write.mode(\"overwrite\").partitionBy(\"state_abbr\", \"gender\").parquet(\"./tables/immigration_record\")\n",
    "airport.write.mode(\"overwrite\").partitionBy(\"iata_code\").parquet(\"./tables/airport\")\n",
    "temperature.write.mode(\"overwrite\").partitionBy(\"City\", \"year\", \"month\").parquet(\"./tables/temperature\")\n",
    "demographic.write.mode(\"overwrite\").partitionBy(\"state_code\", \"City\").parquet(\"./tables/demographic\")\n",
    "immigrant_nationality.write.mode(\"overwrite\").parquet(\"./tables/immigrant_nationality\")\n",
    "visa_table.write.mode(\"overwrite\").parquet(\"./tables/visa_table\")\n",
    "mode_table.write.mode(\"overwrite\").parquet(\"./tables/mode_table\")\n",
    "state_table.write.mode(\"overwrite\").parquet(\"./tables/state_table\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.2 Data Quality Checks\n",
    "Explain the data quality checks you'll perform to ensure the pipeline ran as expected. These could include:\n",
    " * Integrity constraints on the relational database (e.g., unique key, data type, etc.)\n",
    " * Unit tests for the scripts to ensure they are doing the right thing\n",
    " * Source/Count checks to ensure completeness\n",
    " \n",
    "Run Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Perform quality checks here\n",
    "# 1. Check all table exist and is not empty\n",
    "# 2. Check primary key of each table is unique and no null."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# 1. Check whether all tables exist and is not empty\n",
    "\n",
    "def check_table(table_directory = './tables'):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function to perform data quality check to examine whether all required table are presented in our directory,\n",
    "    and check if they all contain value.\n",
    "    \n",
    "    Args:\n",
    "        table_directory (str): the directory that contain all the table in parquet format\n",
    "    \n",
    "    Output:\n",
    "        Print out of messages related to quality check result.\n",
    "    \"\"\"\n",
    "    \n",
    "    from pyspark.sql import SparkSession\n",
    "    spark = SparkSession.builder.\\\n",
    "    config(\"spark.jars.packages\",\"saurfang:spark-sas7bdat:2.0.0-s_2.11\")\\\n",
    "    .enableHiveSupport().getOrCreate()\n",
    "    \n",
    "    # placeholder for table name and its row counts\n",
    "    dict_cnt = {'temperature':0, 'immigrant_nationality':0,'demographic':0,'immigration_record':0, 'state_table':0,'airport':0,'mode_table':0,'visa_table':0}\n",
    "\n",
    "    for table, cnt in dict_cnt.items():\n",
    "        try:\n",
    "            df_test = spark.read.parquet(table_directory+'/'+table)\n",
    "\n",
    "            cnt_test = df_test.count()\n",
    "\n",
    "            # store the row count result\n",
    "            dict_cnt[table] = cnt_test\n",
    "\n",
    "        except Exception:\n",
    "            print(\"Data Quality Check Failed: The table\", table, \"cannot be read with parquet format by Spark, please check if the table is missing.\")\n",
    "\n",
    "    if all(x != 0 for x in dict_cnt.values()):\n",
    "        print(\"Data Quality Check Passed: All table contain value. Row counts for all tables in {table: count} format =>\", str(dict_cnt))\n",
    "    else:\n",
    "        print(\"Data Quality Check Failed: Not all table contain data. Row counts for all tables in {table: count} format =>\", str(dict_cnt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Quality Check Passed: All table contain value. Row counts for all tables in {table: count} format => {'temperature': 2231, 'immigrant_nationality': 289, 'demographic': 2891, 'immigration_record': 3096313, 'state_table': 55, 'airport': 2014, 'mode_table': 4, 'visa_table': 3}\n"
     ]
    }
   ],
   "source": [
    "# run the 1st data quality check\n",
    "check_table('./tables')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# 2. Check primary key of each table is unique and no null.\n",
    "\n",
    "def check_primary_key(table_directory = './tables'):\n",
    "    \n",
    "    dict_table_primary = {'temperature':['City','year','month'], 'immigrant_nationality':['code'],'demographic':['City', 'state_code'],'immigration_record':['id'], 'state_table':['State_abbr'],'airport':['iata_code'],'mode_table':['mode_code'],'visa_table':['visa_code']}\n",
    "    \n",
    "    # placeholder for any data quality issue\n",
    "    all_cnt = 0\n",
    "    \n",
    "    for table, primary in dict_table_primary.items():\n",
    "        try:\n",
    "            df_test = spark.read.parquet(table_directory+'/'+table)\n",
    "        except Exception:\n",
    "            print(\"Data Quality Check Failed: The table\", table, \"cannot be read with parquet format by Spark, please check if the table is missing.\")\n",
    "            all_cnt += 1\n",
    "            continue\n",
    "        \n",
    "        # check duplicate\n",
    "        duplicate_cnt = df_test.groupBy(primary) \\\n",
    "                        .count() \\\n",
    "                        .where(f.col('count') >1) \\\n",
    "                        .select(f.sum('count')) \\\n",
    "                        .collect()[0]['sum(count)']\n",
    "        \n",
    "        if duplicate_cnt != 0 and duplicate_cnt is not None:\n",
    "            print(\"Data Quality Check Failed: The table\", table, \"has\", duplicate_cnt, \"duplicate records in its primary key fields\", primary)\n",
    "            all_cnt += 1\n",
    "            \n",
    "        # check null\n",
    "        null_cnt = 0\n",
    "        \n",
    "        for field in primary:\n",
    "            null_cnt = null_cnt + df_test.filter(df_test[field].isNull()).count()\n",
    "    \n",
    "        if null_cnt != 0:\n",
    "            print(\"Data Quality Check Failed: The table\", table, \"has\", null_cnt, \"null records in its primary key fields\", primary)\n",
    "            all_cnt += 1\n",
    "    \n",
    "    if all_cnt == 0:\n",
    "        print(\"Data Quality Check Passed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Quality Check Passed!\n"
     ]
    }
   ],
   "source": [
    "# run the 2nd data quality check\n",
    "check_primary_key('./tables')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.3 Data dictionary \n",
    "Below is the data dictionary for this data model.\n",
    "\n",
    "1. immigration_record:\n",
    "          id (PK): identification number\n",
    "          year (FK): year of i94\n",
    "          month (FK): month of i94\n",
    "          citizenship: citizenship of the visitor\n",
    "          residence (FK): visitor's residence\n",
    "          airport_code (FK): airport code\n",
    "          arrival_date: arrival date\n",
    "          travel_mode (FK): code for mode of travel\n",
    "          state_abbr (FK): state abbreviation\n",
    "          city (FK): city of the airport\n",
    "          departure_date: departure date\n",
    "          age: age of the visitor\n",
    "          visa_category (FK): visa category\n",
    "          occupation: occupation of the visitor\n",
    "          birth_year: visitor's birthyear\n",
    "          gender: visitor's gender\n",
    "          airline: airline the visitor choose\n",
    "          visatype: visitor's visa type\n",
    "          \n",
    " \n",
    "2. temperature:\n",
    "        City (Composite PK): city\n",
    "        year (Composite PK): year\n",
    "        month (Composite PK): month\n",
    "        Avg_Temperature: average temperature\n",
    "        Avg_Temperature_Uncertainty: average temperature uncertainty range\n",
    "\n",
    "3. demographic:\n",
    "        state_code (Composite PK): state abbreviation\n",
    "        City (Composite PK): city\n",
    "        median_age: median age of the city\n",
    "        male_population: male population count\n",
    "        female_population: female population count\n",
    "        total_population: total population count\n",
    "        number_of_veterans: number of veterans\n",
    "        Foreign-born: number of foreign born\n",
    "        average_household_size: average household size\n",
    "        American_Indian_and_Alaska_Native: count of population of this race\n",
    "        Asian: count of population of this race\n",
    "        Black_or_African-American: count of population of this race\n",
    "        Hispanic_or_Latino: count of population of this race\n",
    "        White: count of population of this race\n",
    "\n",
    "4. airport:\n",
    "        iata_code (PK): iata code of this airport\n",
    "        type: type of the airport\n",
    "        name: name of the airport\n",
    "        elevation_ft: elevation of the airport\n",
    "        continent: continent of the airport\n",
    "        country: country of the airport\n",
    "        state: state of the airport\n",
    "        city: city of the airport\n",
    "        local_code: local code of the airport\n",
    "        gps_code: gps code of the airport\n",
    "        latitude: latitude of the airport\n",
    "        longitude: longitude of the airport\n",
    "\n",
    "5. immigrant_nationality:\n",
    "        code (PK): citizenship and residence code on the immigration_record table\n",
    "        country: corresponding country name \n",
    "\n",
    "6. visa_table:\n",
    "        visa_code (PK): visa_category on the immigration_record table \n",
    "        visa_type: corresponding visa type\n",
    "\n",
    "7. mode_table:\n",
    "        mode_code (PK): travel_mode on the immigration_record table\n",
    "        mode_desc: corresponding mode of travel description\n",
    "\n",
    "8. state_table:\n",
    "        state_abbr (PK): state abbreviation\n",
    "        state_name: state name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Step 5: Complete Project Write Up\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "In this project, we use Spark to perform ETL and create tables for our data model because Spark can process large amount of data with in-memory computing which are more efficient and can scale easily to even larger dataset. Spark also allows loading from various data format and also can be integrated with Cloud computing such as AWS.\n",
    "\n",
    "The proposed update timing should be based on firstly, the reporting need; and secondly, the new data availability. In our case, it may make sense to update monthly because company may want to adjust their following months marketing strategy and message based on at least one month of new data, assuming new data coming out every month.\n",
    "\n",
    "For future development, we can tackle this project with different approaches under the following scenarios:\n",
    " * **If the data was increased by 100x:** We can utilize Cloud computing to host the ETL on Amazon Web Service using Amazon EMR, so that we can easily increase the number of worker nodes based on the necessary data load. This approach allows us to easily scale up or scale out, thereby maintain the desired efficiency.\n",
    " * **If the data populates a dashboard that must be updated on a daily basis by 7am every day:** We can utilize Apache Airflow to perform schedule run following the desired workflow, and furthermore to monitor the workflow and notify us when issues arise, so we can fix issues in a timely manner to meet the requirement.  \n",
    " * **If the database needed to be accessed by 100+ people:** We can put the data model onto Amazon Redshift as our data warehouse on the Cloud. Its massively parallel processing architecture allows multiple users to perform fast querying on large scale of data. And it also allows to add nodes to the data warehouse to maintain fast query performance as the data warehouse grows."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
